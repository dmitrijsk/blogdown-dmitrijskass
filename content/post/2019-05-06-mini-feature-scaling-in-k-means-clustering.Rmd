---
title: 'Mini: feature scaling in k-means clustering'
author: Dmitrijs Kass
date: '2019-05-06'
slug: mini-feature-scaling-in-k-means-clustering
categories:
  - mini
  - clusterings
tags: []
output:
  blogdown::html_page:
    toc: true
draft: false
---

```{r message=FALSE, warning=FALSE}
# Attach packages.
library(tidyverse)

# Import phone data.
phones_df <- read_delim(file = "samsung_dataset.csv", delim = ";", skip = 2)

# Print phone data.
phones_df %>% 
  knitr::kable(col.names = c("Brand", "Model", "Approx. price (EUR)", "Weight (g)"), format = "html") %>% 
  kableExtra::kable_styling(full_width = FALSE, bootstrap_options = c("striped", "condensed"))
```

# Surprise

```{r fig.height=3, fig.width=6}
phones_df %>% 
  ggplot(aes(x = weight_g, y = approx_price_eur)) + 
  geom_point(size = 4, shape = "x") +
  geom_text(aes(label = model), size = 3.5, vjust = "top", nudge_y = -20) +
  scale_x_continuous(expand = expand_scale(mult = 0.3)) +
  scale_y_continuous(expand = expand_scale(mult = 0.3)) +
  labs(title = "How would you assign these 4 phones into 2 clusters?",
       x = "weight (g)", 
       y = "price (EUR)") +
  theme_classic()
```

# K-means clustering with original features

```{r}
# Save columns for clustering in a separate matrix.
phones_mat <- as.matrix(phones_df %>% select(approx_price_eur, weight_g))

# Add rownames to see phone models in a distance matrix.
rownames(phones_mat) <- phones_df$model
```

```{r}
# k-means.
set.seed(1)
kmeans_fit <- kmeans(phones_mat, centers = 2, nstart = 100)

# Small data frame with cluster centers.
centers_df <- kmeans_fit$centers %>%
  as.data.frame() %>% 
  mutate(cluster = 1:2)
```

```{r fig.height=3.5, fig.width=6}
p <- phones_df %>% 
  mutate(cluster = kmeans_fit$cluster) %>% 
  ggplot(aes(x = weight_g, y = approx_price_eur, color = as.factor(cluster))) + 
  geom_point(size = 4, shape = "x") +
  geom_text(aes(label = model), size = 3.5, vjust = "top", nudge_y = -20) +
  geom_point(data = centers_df, size = 4) +
  scale_x_continuous(expand = expand_scale(mult = 0.3)) +
  scale_y_continuous(expand = expand_scale(mult = 0.3)) +
  labs(title = "Hopefully, you are surprised to see Galaxy S8+ alone in cluster 1",
       subtitle = "k-means clustering with original (not scaled) features",
       x = "weight (g)", 
       y = "price (EUR)", 
       color = "Cluster centers") +
  theme_classic() +
  theme(legend.position = "top")

p
```

```{r fig.height=4, fig.width=6, message=FALSE}
# Adjust axes to the same scale.
p +
  labs(title = "No more surprise after equally scaling axes") +
  scale_y_continuous(limits = c(0, 600)) +
  scale_x_continuous(limits = c(0, 600)) +
  coord_equal()
```

# Feature scaling and k-means revisited

Below are Eucledean distances between phones using original features. Values of distances are not interpretable per se because those are euros and grams combined. Magnitudes is what we are interested in. Notice that the distance between "Galaxy S8+" and "Galaxy A7" (190.44) is the second largest distance.

```{r}
round(dist(phones_mat), 2)
```

Now compare it with the same distance calculated from scaled features. It is now 

Distance matrix after feature scaling.

```{r}
phones_mat_scaled <- scale(phones_mat)
round(dist(phones_mat_scaled), 2)
```

<!-- round(dist(phones_mat), 2) %>% as.matrix() %>% as.data.frame() %>% rownames_to_column() %>% gather(model_to, distance, -rowname) %>% filter(rowname == "Galaxy S8+") -->


