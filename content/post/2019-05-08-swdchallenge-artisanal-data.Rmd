---
title: '#SWDchallenge: artisanal data'
author: Dmitrijs Kass
date: '2019-05-08'
slug: swdchallenge-artisanal-data
categories: [data-viz]
tags: []
---

This post is a participation in [#SWDchallenge: artisanal data](http://www.storytellingwithdata.com/blog/2019/5/1/swdchallenge-artisanal-data).

The story is about the words used by 12 guests that appeared on the 14th episode of [#SWDpodcast](http://www.storytellingwithdata.com/podcast).  [Storytelling with Data](http://www.storytellingwithdata.com/book) (SWD) has been on my shelf for over a year and it is this podcast episode that sparkled interest in me about data visualization and made me read the book in few days and start participating in data viz challenges.

Analysis below is performed in [R](https://www.r-project.org/), a free software environment for statistical computing and graphics with the help of [tidyverse](https://www.tidyverse.org/) packages and text analysis packages (`tidytext`, `tm`, `textstem`, `qdap`).

# Data 

The source of data is the [transcript](https://docs.google.com/document/d/1S2_63MUbvQs7fxWQrcuCNSl03fmDl1Vr3FjNjnbWK14/edit#) of episode 14 of #SWDpodcast brought by SWD. As the goal is to analyse words used by the guests of the podcast, the initial step is to clean data from all other text.

# Text cleaning

## Steps

Text cleaning for this analysis involves five main steps:

1. Extract the monologues of the 12 podcast guests from the transcript.
2. Replace [contractions](https://en.wikipedia.org/wiki/Contraction_(grammar)). For example:

```{r}
qdap::replace_contraction("It's a fascinating field")
```

3. Split sentences into single words, [unigrams](https://en.wikipedia.org/wiki/N-gram). For example:

```{r message=FALSE, warning=FALSE}
library(tidyverse)
example <- tibble(sentense = "I learned R and started doing visualizations in R") %>% 
  tidytext::unnest_tokens(output = "word", input = sentense, token = "words")
example
```

4. [Lemmatize](https://en.wikipedia.org/wiki/Lemmatisation) words. For example:

```{r}
example <- mutate(example, word_lemma = textstem::lemmatize_words(word))
example
```

5. Remove [stop words](https://en.wikipedia.org/wiki/Stop_words). Stop words from the [SMART information retrieval system](http://www.jmlr.org/papers/volume5/lewis04a/lewis04a.pdf) available in `tm` package served as the basis and were adjusted for the purpose of this analysis[^1]. For example:

```{r}
example <- mutate(example, stop_word = word %in% tm::stopwords(kind = "SMART"))
example
```


## Results 

```{r}

```




[^1]: SMART stop words were supplemented with the names of podcast host and guests. One stop word was removed, it is a letter *"r"*, which is used by one of the podcast guests to refer to R as a software. It is definitely worth knowing prepackaged stop words!
